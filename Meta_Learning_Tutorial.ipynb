{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meta_Learning_Tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayeonLee/Meta_Learning_Tutorial/blob/master/Meta_Learning_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGTx_OObbKFr",
        "colab_type": "text"
      },
      "source": [
        "Original Code: https://github.com/abdulfatir/prototypical-networks-tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gByYJhbkIFC",
        "colab_type": "text"
      },
      "source": [
        "# Few-shot Learning 1: Prototypical Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n8mp-NtkdX8",
        "colab_type": "text"
      },
      "source": [
        "이 튜토리얼에서 우리는 meta knowledge를 학습하여 few-shot learning을 수행하는 두가지 대표적인 네트워크, [Prototypical Network](https://arxiv.org/abs/1703.05175) (ProtoNet)과 [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400) (MAML)을 배울 것입니다.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Raty31ll3_V",
        "colab_type": "text"
      },
      "source": [
        "## Few-shot Learning이란?\n",
        "(설명 추가 예정)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UytiQzugmFwS",
        "colab_type": "text"
      },
      "source": [
        "## Prototypical Network란?\n",
        "(설명 추가 예정)\n",
        "![대체 텍스트](https://drive.google.com/uc?id=1mdv1z3BlFzJm3SaAWW2hajs9eqoXU5qe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ibNMiX3mQWU",
        "colab_type": "text"
      },
      "source": [
        "## ProtoNet 튜토리얼\n",
        "\n",
        "이제부터 어떻게 네트워크를 만들고 ProtoNet 학습 시킬지를 배워봅시다.\n",
        "순서는 다음과 같습니다.\n",
        "0. 데이터셋을 다운로드 받는다.\n",
        "1. Tensorflow와 다른 library들을 불러온다.\n",
        "2. 데이터셋을 전처리한다.\n",
        "3. 모델을 만든다.\n",
        "4. loss와 optimizer를 정의한다.\n",
        "5. Training loop를 정의한다.\n",
        "6. Training!\n",
        "7. Test\n",
        "\n",
        "그럼 하나씩 진행해보도록 합시다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3etol1Too-H",
        "colab_type": "text"
      },
      "source": [
        "### Download Omniglot Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WIHVdo7bKn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data/omniglot/data\n",
        "!mkdir -p data/omniglot/split\n",
        "!wget -O data/omniglot/split/trainval.txt https://github.com/kvpratama/prototypical-networks-tensorflow/blob/master/data/omniglot/splits/trainval.txt?raw=true\n",
        "!wget -O data/omniglot/split/train.txt https://github.com/kvpratama/prototypical-networks-tensorflow/blob/master/data/omniglot/splits/train.txt?raw=true\n",
        "!wget -O data/omniglot/split/test.txt https://github.com/kvpratama/prototypical-networks-tensorflow/blob/master/data/omniglot/splits/test.txt?raw=true\n",
        "!wget -O images_background.zip https://github.com/brendenlake/omniglot/blob/master/python/images_background.zip?raw=true\n",
        "!wget -O images_evaluation.zip https://github.com/brendenlake/omniglot/blob/master/python/images_evaluation.zip?raw=true\n",
        "!unzip images_background.zip -d data/omniglot/data\n",
        "!unzip images_evaluation.zip -d data/omniglot/data\n",
        "!mv data/omniglot/data/images_background/* data/omniglot/data/\n",
        "!mv data/omniglot/data/images_evaluation/* data/omniglot/data/\n",
        "!rmdir data/images_background\n",
        "!rmdir data/images_evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "### Import Tensorflow and other libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ql58Q8zHDxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-9soydBCVt2",
        "colab_type": "code",
        "outputId": "0f67f9f1-0154-431b-fc76-67eb48d46c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "#기존에 설치된 다른 버전의 tensorflow를 제거합니다.\n",
        "!pip uninstall tensorboard -y\n",
        "!pip uninstall tensorflow-gpu -y\n",
        "!pip uninstall tensorflow -y"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorboard-1.14.0:\n",
            "  Successfully uninstalled tensorboard-1.14.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "Uninstalling tensorflow-1.14.0:\n",
            "  Successfully uninstalled tensorflow-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo0Omp5ZHWoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.14.0 #tensorflow gpu 버전을 설치합니다"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1dXdGsTwgnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf # tensorflow를 import해줍니다"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SocdF2LhxX4R",
        "colab_type": "code",
        "outputId": "4c833d99-9ca8-4005-f23d-684c7a8315f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__ # 내가 사용할 tensorflow의 버전을 나타냅니다"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36vlWPtzaJMA",
        "colab_type": "code",
        "outputId": "829c98be-5faa-4c05-b03d-4817912e36fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if tf.test.gpu_device_name():\n",
        "  print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "  print(\"Please install GPU version of TF\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Default GPU Device: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uti2MrBxZKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 필요한 라이브러리를 import합니다.\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU5zrjlgn5-y",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the dataset\n",
        "\n",
        "Omniglot 데이터셋을 이용하여 ProtoNet를 학습시켜봅시다.\n",
        "\n",
        "학습이 끝나면 ProtoNet은 처음 보는 Task들에 대해서 few-shot classification을 잘 수행하게 됩니다.\n",
        "\n",
        "주어진 정보들을 이용하여 빈 칸을 채워보세요! ([    ]가 빈 칸을 나타냅니다. 괄호를 지우고 알맞은 코드를 써주세요)\n",
        "\n",
        "1. 매 epoch마다 100가지의 다른 에피소드가 주어집니다.\n",
        "2. 매 에피소드마다 태스크의 분류해야할 클래스의 종류는 60개입니다.\n",
        "3. 태스크의 각 클래스 별로 참고 할 수 있도록 주어진 이미지는 5개입니다.\n",
        "4. 태스크의 각 클래스 별로 맞춰야할 이미지는 5개입니다.\n",
        "5. 이미지는 흑백 이미지로 단일 채널입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFKrv8aaxm07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 20 # epoch 수\n",
        "n_episodes = 100 # 1번\n",
        "n_way = 60 # 2번\n",
        "n_shot = 5 # 3번\n",
        "n_query = 5 # 4번\n",
        "n_examples = 20\n",
        "im_width = 28 # 이미지 넓이\n",
        "im_height = 28 # 이미지 높이\n",
        "channels = 1 # 5번"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrJkolFJxpBi",
        "colab_type": "code",
        "outputId": "77fe5f2d-929b-423c-bd72-828f0731f057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 훈련 데이터 셋을 불러옵니다.\n",
        "root_dir = './data/omniglot' \n",
        "train_split_path = os.path.join(root_dir, 'split', 'train.txt') # 경로: ./data/omniglot/split/train.txt\n",
        "\n",
        "# 모든 클래스의 경로를 train_classes 리스트에 저장합니다.\n",
        "with open(train_split_path, 'r') as train_split:\n",
        "    train_classes = [line.rstrip() for line in train_split.readlines()] \n",
        "n_classes = len(train_classes)\n",
        "\n",
        "# 각 클래스별 모든 이미지의 경로를 불러옵니다.\n",
        "train_dataset = np.zeros([n_classes, n_examples, im_height, im_width], dtype=np.float32)\n",
        "for i, tc in enumerate(train_classes):\n",
        "    alphabet, character, rotation = tc.split('/')\n",
        "    rotation = float(rotation[3:])\n",
        "    im_dir = os.path.join(root_dir, 'data', alphabet, character)\n",
        "    im_files = sorted(glob.glob(os.path.join(im_dir, '*.png')))\n",
        "    # 이미지를 불러들여 회전, 크기 변환, 형 변환 등을 수행한 뒤 train_dataset 행렬에 저장합니다.\n",
        "    for j, im_file in enumerate(im_files):\n",
        "        im = 1. - np.array(Image.open(im_file).rotate(rotation).resize((im_width, im_height)), np.float32, copy=False)\n",
        "        train_dataset[i, j] = im\n",
        "c, ni, w, h = train_dataset.shape\n",
        "print('불러온 훈련 데이터 셋의 특징')\n",
        "print('클래스 갯수: {}, 클래스 별 이미지 갯수: {}, 이미지 넓이: {}, 이미지 높이: {}'.format(c, ni, w, h))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "클래스 갯수: 4112, 클래스 별 이미지 갯수: 20, 이미지 넓이: 28, 이미지 높이: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWbktzzmveYQ",
        "colab_type": "text"
      },
      "source": [
        "## Create the models\n",
        "이제 Prototypical Network를 만들어봅시다!\n",
        "\n",
        "우리가 만들 Prototypical Network의 구조는 아래 그림들과 같습니다.\n",
        "![대체 텍스트](https://drive.google.com/uc?id=1nBP6VvWyDLb_kGmg3a_oEk4FP0oJSiXa)\n",
        "\n",
        "빈 칸을 채워서 그림과 맞는 모델을 만들어보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DGC7Hd92nE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h_dim = 64 # hidden channels\n",
        "z_dim = 64 # output channels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF1PXufnxeth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(inputs, out_channels, name='conv'):\n",
        "    with tf.variable_scope(name):\n",
        "        conv = tf.layers.conv2d(inputs, out_channels, kernel_size=3, padding='SAME')\n",
        "        conv = tf.contrib.layers.batch_norm(conv, updates_collections=None, decay=0.99, scale=True, center=True)\n",
        "        conv = tf.nn.relu(conv)\n",
        "        conv = tf.contrib.layers.max_pool2d(conv, 2)\n",
        "        return conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZM-QxRbxjb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder(x, h_dim, z_dim, reuse=False):\n",
        "    with tf.variable_scope('encoder', reuse=reuse):\n",
        "        net = conv_block(x, h_dim, name='Conv_Block_1')\n",
        "        net = conv_block(net, h_dim, name='Conv_Block_2')\n",
        "        net = conv_block(net, h_dim, name='Conv_Block_3')\n",
        "        net = conv_block(net, z_dim, name='Conv_Block_4')\n",
        "        net = tf.contrib.layers.flatten(net)\n",
        "        return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17AATWLZ36Jg",
        "colab_type": "text"
      },
      "source": [
        "## Define metric function: Euclidean distance\n",
        "\n",
        "\\begin{equation*}\n",
        "d(z, z') = ||z-z'||^2\n",
        "\\end{equation*}\n",
        "\\begin{equation*}\n",
        "d(f_\\phi(\\mathbf{x}), \\mathbf{c}_k)) = ||f_\\phi(\\mathbf{x})-\\mathbf{c}_k||^2\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn7o4x-RxlGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# N개의 임베딩 벡터와 M개의 임베딩 벡터 간의 유클리디안 거리를 계산합니다.\n",
        "def euclidean_distance(a, b):\n",
        "    # a.shape = N x D\n",
        "    # b.shape = M x D\n",
        "    N, D = tf.shape(a)[0], tf.shape(a)[1]\n",
        "    M = tf.shape(b)[0]\n",
        "    a = tf.tile(tf.expand_dims(a, axis=1), (1, M, 1))\n",
        "    b = tf.tile(tf.expand_dims(b, axis=0), (N, 1, 1))\n",
        "    return tf.reduce_mean(tf.square(a - b), axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqfY86MC4ebX",
        "colab_type": "text"
      },
      "source": [
        "## Set placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svY5Oxd-3h6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "supports = tf.placeholder(tf.float32, [None, None, im_height, im_width, channels])\n",
        "queries = tf.placeholder(tf.float32, [None, None, im_height, im_width, channels])\n",
        "support_shape = tf.shape(supports)\n",
        "query_shape = tf.shape(queries)\n",
        "num_classes, num_support = support_shape[0], support_shape[1]\n",
        "num_queries = query_shape[1]\n",
        "y = tf.placeholder(tf.int64, [None, None])\n",
        "y_one_hot = tf.one_hot(y, depth=num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rsunr7ou51wL",
        "colab_type": "text"
      },
      "source": [
        "## Get prototypes and query embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ9cKGLCIzv5",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://drive.google.com/uc?id=1mN4CNa9AOq2nQjK8hvXN7KztZHwZoLDE)\n",
        "\n",
        "Support 포인트들을 평균 내서 클래스별 프로토타입을 구하고 쿼리 포인트들은 인스턴스로 임베딩 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbTwRNVr55G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# support 이미지를 임베딩 벡터로 인코딩합니다.\n",
        "emb_supports = encoder(tf.reshape(supports, [num_classes * num_support, im_height, im_width, channels]), h_dim, z_dim)\n",
        "emb_dim = tf.shape(emb_supports)[-1]\n",
        "# 각 클래스의 support 임베딩들의 평균을 구하여 각 클래스별 프로토타입을 얻습니다.\n",
        "prototypes = tf.reduce_mean(tf.reshape(emb_supports, [num_classes, num_support, emb_dim]), axis=1)\n",
        "# 주어진 쿼리를 임베딩 벡터로 인코딩합니다.\n",
        "emb_queries = encoder(tf.reshape(queries, [num_classes * num_queries, im_height, im_width, channels]), h_dim, z_dim, reuse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Gcama45OZF",
        "colab_type": "text"
      },
      "source": [
        "## Get prototypical loss with Euclidean distance\n",
        "\n",
        "![대체 텍스트](https://drive.google.com/uc?id=1LBkqCntsBNiP7RyaCazXopswhslabhJE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S74DnmHm4-Ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 쿼리 임베딩들과 프로토타입들 간의 유클리디안 거리를 계산합니다.\n",
        "dists = euclidean_distance(emb_queries, prototypes)\n",
        "# \n",
        "log_p_y = tf.reshape(tf.nn.log_softmax(-dists), [num_classes, num_queries, -1])\n",
        "ce_loss = -tf.reduce_mean(tf.reshape(tf.reduce_sum(tf.multiply(y_one_hot, log_p_y), axis=-1), [-1]))\n",
        "acc = tf.reduce_mean(tf.to_float(tf.equal(tf.argmax(log_p_y, axis=-1), y)))\n",
        "\n",
        "train_op = tf.train.AdamOptimizer().minimize(ce_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4bc4V2X04N9",
        "colab_type": "text"
      },
      "source": [
        "## Set session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v9ZZq8zx7ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "init_op = tf.global_variables_initializer()\n",
        "sess.run(init_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5BQ0vIH4j8o",
        "colab_type": "text"
      },
      "source": [
        "## Let's run the code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvGMxVEj9Y7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ep in range(n_epochs):\n",
        "    for epi in range(n_episodes):\n",
        "        epi_classes = np.random.permutation(n_classes)[:n_way]\n",
        "        support = np.zeros([n_way, n_shot, im_height, im_width], dtype=np.float32)\n",
        "        query = np.zeros([n_way, n_query, im_height, im_width], dtype=np.float32)\n",
        "        for i, epi_cls in enumerate(epi_classes):\n",
        "            selected = np.random.permutation(n_examples)[:n_shot + n_query]\n",
        "            support[i] = train_dataset[epi_cls, selected[:n_shot]]\n",
        "            query[i] = train_dataset[epi_cls, selected[n_shot:]]\n",
        "        support = np.expand_dims(support, axis=-1)\n",
        "        query = np.expand_dims(query, axis=-1)\n",
        "        labels = np.tile(np.arange(n_way)[:, np.newaxis], (1, n_query)).astype(np.uint8)\n",
        "        _, ls, ac = sess.run([train_op, ce_loss, acc], feed_dict={x: support, q: query, y:labels})\n",
        "        if (epi+1) % 50 == 0:\n",
        "            print('[epoch {}/{}, episode {}/{}] => loss: {:.5f}, acc: {:.5f}'.format(ep+1, n_epochs, epi+1, n_episodes, ls, ac))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzc7lDeiJxsu",
        "colab_type": "text"
      },
      "source": [
        "## Visualization\n",
        "\n",
        "![대체 텍스트](https://drive.google.com/uc?id=1fx5bVyr-VTHjtW21bWGt-LeghmQ3Iaom)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF_20TVDJ-GV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx8gxw6D4uhq",
        "colab_type": "text"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVXaYPolYYN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Test Dataset\n",
        "root_dir = './data/omniglot'\n",
        "test_split_path = os.path.join(root_dir, 'splits', 'test.txt')\n",
        "with open(test_split_path, 'r') as test_split:\n",
        "    test_classes = [line.rstrip() for line in test_split.readlines()]\n",
        "n_test_classes = len(test_classes)\n",
        "test_dataset = np.zeros([n_test_classes, n_examples, im_height, im_width], dtype=np.float32)\n",
        "for i, tc in enumerate(test_classes):\n",
        "    alphabet, character, rotation = tc.split('/')\n",
        "    rotation = float(rotation[3:])\n",
        "    im_dir = os.path.join(root_dir, 'data', alphabet, character)\n",
        "    im_files = sorted(glob.glob(os.path.join(im_dir, '*.png')))\n",
        "    for j, im_file in enumerate(im_files):\n",
        "        im = 1. - np.array(Image.open(im_file).rotate(rotation).resize((im_width, im_height)), np.float32, copy=False)\n",
        "        test_dataset[i, j] = im\n",
        "print(test_dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpM94xXO7zoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_test_episodes = 1000\n",
        "n_test_way = 20\n",
        "n_test_shot = 5\n",
        "n_test_query = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIavKTO872iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Testing...')\n",
        "avg_acc = 0.\n",
        "for epi in range(n_test_episodes):\n",
        "    epi_classes = np.random.permutation(n_test_classes)[:n_test_way]\n",
        "    support = np.zeros([n_test_way, n_test_shot, im_height, im_width], dtype=np.float32)\n",
        "    query = np.zeros([n_test_way, n_test_query, im_height, im_width], dtype=np.float32)\n",
        "    for i, epi_cls in enumerate(epi_classes):\n",
        "        selected = np.random.permutation(n_examples)[:n_test_shot + n_test_query]\n",
        "        support[i] = test_dataset[epi_cls, selected[:n_test_shot]]\n",
        "        query[i] = test_dataset[epi_cls, selected[n_test_shot:]]\n",
        "    support = np.expand_dims(support, axis=-1)\n",
        "    query = np.expand_dims(query, axis=-1)\n",
        "    labels = np.tile(np.arange(n_test_way)[:, np.newaxis], (1, n_test_query)).astype(np.uint8)\n",
        "    ls, ac = sess.run([ce_loss, acc], feed_dict={x: support, q: query, y:labels})\n",
        "    avg_acc += ac\n",
        "    if (epi+1) % 50 == 0:\n",
        "        print('[test episode {}/{}] => loss: {:.5f}, acc: {:.5f}'.format(epi+1, n_test_episodes, ls, ac))\n",
        "avg_acc /= n_test_episodes\n",
        "print('Average Test Accuracy: {:.5f}'.format(avg_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}